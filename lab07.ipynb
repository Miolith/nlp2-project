{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "7332108a75c0432197890eb65a1750e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_de537907051645bd8af8ddee4df6d1c9",
              "IPY_MODEL_907050fb812146d5822d4dac90ada81b",
              "IPY_MODEL_c09441d6b1074b5d8313d61e4d15b9a2"
            ],
            "layout": "IPY_MODEL_70b13e860359406b8db282bb5152d210"
          }
        },
        "de537907051645bd8af8ddee4df6d1c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_734baa579df34629a5761f97a8ac2f14",
            "placeholder": "​",
            "style": "IPY_MODEL_092d0458a250465ea5205fbd07d4004c",
            "value": "100%"
          }
        },
        "907050fb812146d5822d4dac90ada81b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cd8433e12d6f4fc4913d03cfdd2fb6c9",
            "max": 4635922,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_76adcfd15e5f4e29b14895c33cbb8f52",
            "value": 4635922
          }
        },
        "c09441d6b1074b5d8313d61e4d15b9a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3c084329951e4eabbc00ca617c9d8bdc",
            "placeholder": "​",
            "style": "IPY_MODEL_7fc2124791014799a889a823c3af0ade",
            "value": " 4635922/4635922 [00:35&lt;00:00, 87131.39it/s]"
          }
        },
        "70b13e860359406b8db282bb5152d210": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "734baa579df34629a5761f97a8ac2f14": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "092d0458a250465ea5205fbd07d4004c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cd8433e12d6f4fc4913d03cfdd2fb6c9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "76adcfd15e5f4e29b14895c33cbb8f52": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3c084329951e4eabbc00ca617c9d8bdc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7fc2124791014799a889a823c3af0ade": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# NLP 2 LAB 03 -  Semantic Search"
      ],
      "metadata": {
        "id": "5MLLok4GbT53"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "3JQ4yPVO241t"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install beir tensorflow_text sentence_transformers hnswlib"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from beir import util as b_util, LoggingHandler\n",
        "from beir.retrieval import models\n",
        "from beir.datasets.data_loader import GenericDataLoader\n",
        "from beir.retrieval.evaluation import EvaluateRetrieval\n",
        "from beir.retrieval.search.dense import DenseRetrievalExactSearch as DRES\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sentence_transformers import util\n",
        "from tqdm import tqdm\n",
        "from time import time\n",
        "\n",
        "import numpy as np\n",
        "import logging\n",
        "import random\n",
        "\n",
        "random.seed(42)"
      ],
      "metadata": {
        "id": "dH4G-anTwx5z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3726c322-1a66-409b-9033-dc75517de8a3"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/beir/util.py:2: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
            "  from tqdm.autonotebook import tqdm\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## (8 points) Create a searchable index\n",
        "---"
      ],
      "metadata": {
        "id": "WiahGP2odccr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#### Download dbpedia-entity.zip dataset and unzip the dataset\n",
        "dataset = \"dbpedia-entity\"\n",
        "url = \"https://public.ukp.informatik.tu-darmstadt.de/thakur/BEIR/datasets/{}.zip\".format(dataset)\n",
        "out_dir = \".\"\n",
        "data_path = b_util.download_and_unzip(url, out_dir)\n",
        "\n",
        "#### Provide the data_path where dbpedia-entity has been downloaded and unzipped\n",
        "corpus, queries, qrels = GenericDataLoader(data_folder=data_path).load(split=\"test\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "7332108a75c0432197890eb65a1750e7",
            "de537907051645bd8af8ddee4df6d1c9",
            "907050fb812146d5822d4dac90ada81b",
            "c09441d6b1074b5d8313d61e4d15b9a2",
            "70b13e860359406b8db282bb5152d210",
            "734baa579df34629a5761f97a8ac2f14",
            "092d0458a250465ea5205fbd07d4004c",
            "cd8433e12d6f4fc4913d03cfdd2fb6c9",
            "76adcfd15e5f4e29b14895c33cbb8f52",
            "3c084329951e4eabbc00ca617c9d8bdc",
            "7fc2124791014799a889a823c3af0ade"
          ]
        },
        "id": "60_M58aY4sQy",
        "outputId": "7f6efce0-48ff-4c92-9c6d-fe7cfd061fa1"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/4635922 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7332108a75c0432197890eb65a1750e7"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### (1 point) Explain the data structure. What are the three values returned by Beir, and how are they presented."
      ],
      "metadata": {
        "id": "ep9jHjCvdhfU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Display dataset features\n",
        "print(\"Number of documents in the corpus: {}\".format(len(corpus)))\n",
        "print(\"Number of queries: {}\".format(len(queries)))\n",
        "print(\"Number of qrels: {}\".format(len(qrels)))\n",
        "\n",
        "# Display a sample query\n",
        "print(\"Sample query: {}\".format(next(iter(queries.items()))))\n",
        "\n",
        "# Display a sample document\n",
        "print(\"Sample document: {}\".format(next(iter(corpus.items()))))\n",
        "\n",
        "# Display a sample qrel\n",
        "print(\"Sample qrel: {}\".format(next(iter(qrels.items()))))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "orHhBg1g6FsT",
        "outputId": "f61d1ebb-183a-471c-f5f2-f7a181254aad"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of documents in the corpus: 4635922\n",
            "Number of queries: 400\n",
            "Number of qrels: 400\n",
            "Sample query: ('INEX_LD-2009022', 'Szechwan dish food cuisine')\n",
            "Sample document: ('<dbpedia:Animalia_(book)>', {'text': \"Animalia is an illustrated children's book by Graeme Base. It was originally published in 1986, followed by a tenth anniversary edition in 1996, and a 25th anniversary edition in 2012. Over three million copies have been sold.   A special numbered and signed anniversary edition was also published in 1996, with an embossed gold jacket.\", 'title': 'Animalia (book)'})\n",
            "Sample qrel: ('INEX_LD-2009022', {'<dbpedia:Afghan_cuisine>': 0, '<dbpedia:Akan_cuisine>': 0, '<dbpedia:Ambuyat>': 0, '<dbpedia:American_Chinese_cuisine>': 1, '<dbpedia:Ants_climbing_a_tree>': 2, '<dbpedia:Baingan_bharta>': 1, '<dbpedia:Bamischijf>': 0, '<dbpedia:Black_cardamom>': 0, '<dbpedia:Brazilian_cuisine>': 0, '<dbpedia:British_cuisine>': 0, '<dbpedia:Caribbean_cuisine>': 0, '<dbpedia:Cellophane_noodles>': 1, '<dbpedia:Ceviche>': 0, '<dbpedia:Chana_masala>': 0, '<dbpedia:Chen_Kenichi>': 1, '<dbpedia:Chen_Kenmin>': 1, '<dbpedia:Chicago-style_pizza>': 0, '<dbpedia:Chicken_(food)>': 0, '<dbpedia:Chifle>': 0, '<dbpedia:Chili_oil>': 2, '<dbpedia:Chinatown,_Los_Angeles>': 0, '<dbpedia:Chinatown>': 1, '<dbpedia:Chinese_cuisine>': 2, '<dbpedia:Churumuri_(food)>': 0, '<dbpedia:Cookbook>': 0, '<dbpedia:Cooking>': 0, '<dbpedia:Couscous>': 0, '<dbpedia:Cuban_cuisine>': 0, '<dbpedia:Cuisine>': 0, '<dbpedia:Cuisine_of_Jharkhand>': 0, '<dbpedia:Cuisine_of_the_Southern_United_States>': 0, '<dbpedia:Cuisine_of_the_United_States>': 0, '<dbpedia:Culture_of_the_Song_dynasty>': 0, '<dbpedia:Curry>': 0, '<dbpedia:Dal_dhokli>': 0, '<dbpedia:Ding_Baozhen>': 0, '<dbpedia:Dish_(food)>': 0, '<dbpedia:Doubanjiang>': 1, '<dbpedia:Drunken_shrimp>': 0, '<dbpedia:Escabeche>': 0, '<dbpedia:Fermentation_in_food_processing>': 0, '<dbpedia:Food_presentation>': 0, '<dbpedia:Fried_rice>': 0, '<dbpedia:Fuchsia_Dunlop>': 1, '<dbpedia:Fufu>': 0, '<dbpedia:Fuqi_feipian>': 2, '<dbpedia:Gastronomy>': 0, \"<dbpedia:General_Tso's_chicken>\": 0, '<dbpedia:German_cuisine>': 0, '<dbpedia:Ghanaian_cuisine>': 0, '<dbpedia:Global_cuisine>': 0, '<dbpedia:Gondi_dumpling>': 0, '<dbpedia:Greek_cuisine>': 0, '<dbpedia:Guizhou_cuisine>': 1, '<dbpedia:Guoba>': 2, '<dbpedia:Ham_salad>': 0, '<dbpedia:Harees>': 0, '<dbpedia:Hazaragi_cuisine>': 0, '<dbpedia:History_of_Chinese_cuisine>': 1, '<dbpedia:Hong_Kong_cuisine>': 0, '<dbpedia:Hot_and_sour_soup>': 1, '<dbpedia:Hot_pot>': 2, '<dbpedia:Hot_sauce>': 1, '<dbpedia:Huaiyang_cuisine>': 0, '<dbpedia:Hunan_cuisine>': 0, '<dbpedia:Indian_Chinese_cuisine>': 1, '<dbpedia:Indian_Singaporean_cuisine>': 0, '<dbpedia:Indian_cuisine>': 0, '<dbpedia:Indonesian_cuisine>': 0, '<dbpedia:Italian_cuisine>': 0, '<dbpedia:Kebab>': 0, '<dbpedia:Khmer_(food)>': 0, '<dbpedia:Knieperkohl>': 0, '<dbpedia:Korean_cuisine>': 0, '<dbpedia:Korean_royal_court_cuisine>': 0, '<dbpedia:Kung_Pao_chicken>': 1, '<dbpedia:Latin_American_cuisine>': 0, '<dbpedia:Lechon>': 0, '<dbpedia:List_of_Asian_cuisines>': 0, '<dbpedia:List_of_Chinese_dishes>': 1, '<dbpedia:List_of_cuisines>': 0, '<dbpedia:List_of_egg_dishes>': 0, '<dbpedia:List_of_foods>': 0, '<dbpedia:List_of_potato_dishes>': 0, '<dbpedia:Mala_sauce>': 2, '<dbpedia:Malay_cuisine>': 0, '<dbpedia:Mangú>': 0, '<dbpedia:Mapo_doufu>': 2, '<dbpedia:Mexican_cuisine>': 0, '<dbpedia:National_dish>': 0, '<dbpedia:Omelette>': 0, '<dbpedia:Osh_(food)>': 0, '<dbpedia:Outline_of_cuisines>': 0, '<dbpedia:Outline_of_food_preparation>': 0, '<dbpedia:Pao_cai>': 1, '<dbpedia:Pasta>': 0, '<dbpedia:Philippine_cuisine>': 0, '<dbpedia:Pichanga_(dish)>': 0, '<dbpedia:Pilaf>': 0, '<dbpedia:Porridge>': 0, '<dbpedia:Regional_cuisine>': 0, '<dbpedia:Roast_beef>': 0, '<dbpedia:Run_down>': 0, '<dbpedia:Sanna_(dish)>': 0, '<dbpedia:Seafood_dishes>': 0, '<dbpedia:Shuizhu>': 2, '<dbpedia:Shun_Lee_Palace>': 0, '<dbpedia:Sichuan>': 1, '<dbpedia:Sichuan_cuisine>': 1, '<dbpedia:Sichuan_pepper>': 1, '<dbpedia:Side_dish>': 0, '<dbpedia:Sinki_(food)>': 1, '<dbpedia:Staple_food>': 0, '<dbpedia:Street_food>': 0, '<dbpedia:Suanla_chaoshou>': 2, '<dbpedia:Sundanese_cuisine>': 0, '<dbpedia:Tahini>': 0, '<dbpedia:Taiwanese_cuisine>': 0, '<dbpedia:Thai_cuisine>': 0, '<dbpedia:Tongue>': 0, '<dbpedia:Traditional_food>': 0, '<dbpedia:Turkish_cuisine>': 0, '<dbpedia:Twelve-dish_Christmas_Eve_supper>': 0, '<dbpedia:Twice_cooked_pork>': 2, '<dbpedia:Urap>': 0, '<dbpedia:Vicia_faba>': 1, '<dbpedia:Wonton>': 1, '<dbpedia:Zha_cai>': 1, '<dbpedia:Zhal>': 0, '<dbpedia:Zhangcha_duck>': 1, '<dbpedia:Zigong>': 0})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Le dataset est constitué de trois composantes :**\n",
        "- Dictionnaire de *4 635 922* documents issus des pages de DBpedia avec le contenu `text` et le titre `title` (corpus)\n",
        "- Dictionnaire de *400* requêtes (queries)\n",
        "- Les pages pertinentes vers lesquelles chaque requête est censée rediriger (qrels)"
      ],
      "metadata": {
        "id": "ydmB6JhNeBRb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### (2 points) To ease the problem, extract all the document from the corpus which are relevant to at least one query. Then, add 100K random documents which are not relevant to any query. Make sure the process is reproducible by setting the random seed on whatever random sampling method you use."
      ],
      "metadata": {
        "id": "wutDbcFcgPW1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "relevant_docs = set()\n",
        "for qid, q_rels in qrels.items():\n",
        "    for docid, num in q_rels.items():\n",
        "        if num > 0:\n",
        "            relevant_docs.add(docid)\n",
        "\n",
        "# Add 100K random documents which are not relevant to any query\n",
        "random_docs = random.sample(list(set(corpus.keys()) - relevant_docs), 100_000)\n",
        "\n",
        "# Create a new corpus with the relevant and random documents\n",
        "new_corpus = {docid: corpus[docid] for docid in relevant_docs.union(random_docs)}"
      ],
      "metadata": {
        "id": "YMk1lZ1D8xWT"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display a sample of the new corpus\n",
        "next(iter(new_corpus.items()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zcMRrneWwvum",
        "outputId": "bdf9fc2b-210e-4754-f3fd-41af945d4bd7"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('<dbpedia:Parties_in_the_European_Council_during_2007>',\n",
              " {'text': 'This article describes the party affiliations of leaders of each member-state represented in the European Council during the year 2007. The list below gives the political party that each head of government, or head of state, belongs to at the national level, as well as the European political alliance to which that national party belongs. The states are listed from most to least populous.',\n",
              "  'title': 'Parties in the European Council during 2007'})"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, we should be ready to start experimenting with our smaller dataset. Use the sentence-transformers library to index your dataset. As queries and documents are different, use an asymetric similarity models. Pick one model across the ones proposed. Make sure to document your choice, and why you picked it (because of accuracy, speed, ...)."
      ],
      "metadata": {
        "id": "2PDaQe3WhzBo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "model = SentenceTransformer('msmarco-distilbert-base-v4').to(\"cuda\")"
      ],
      "metadata": {
        "id": "1BvF7hSfvrBB"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nous avons choisi ce model car il s'agit de celui avec la meilleure accuracy parmi les modèles entraînés pour la *cosine similarity*. On perd en vitesse d'exécution par requête mais compte tenu de la puissance de calcul de Google Colab, du GPU et des optimizations appliquées ci-dessous, cette perte est négligeable. "
      ],
      "metadata": {
        "id": "iiXSIjeTu--n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### (2 points) Embed the reduced corpus and the queries using the chosen model."
      ],
      "metadata": {
        "id": "fjSiu90lk_XD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "corpus_embeddings = model.encode([doc[\"text\"] for doc in new_corpus.values()], convert_to_tensor=True)\n",
        "query_embeddings = model.encode(list(queries.values()), convert_to_tensor=True)\n",
        "\n",
        "print(\"We eventually get embeddings of dimension:\", corpus_embeddings.shape)"
      ],
      "metadata": {
        "id": "FvQNXi-qp674",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d2dfe52-b6c9-4a5a-b229-aca4c6aed7f5"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "We eventually get embeddings of dimension: torch.Size([114877, 768])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Optimizing the queries:\n",
        "# We send the tensors to the cuda device and normalize embeddings\n",
        "# so we can compute the inner product instead of the cosine\n",
        "\n",
        "corpus_embeddings = corpus_embeddings.to('cuda')\n",
        "corpus_embeddings = util.normalize_embeddings(corpus_embeddings)\n",
        "\n",
        "query_embeddings = query_embeddings.to('cuda')\n",
        "query_embeddings = util.normalize_embeddings(query_embeddings)"
      ],
      "metadata": {
        "id": "70QW12M8qHL-"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Update qrels with new corpus ids and query ids\n",
        "new_qrels = {}\n",
        "for id, (qid, q_rels) in enumerate(qrels.items()):\n",
        "    new_qrels[id] = {}\n",
        "    for docid, val in q_rels.items():\n",
        "        if docid in new_corpus and val > 0:\n",
        "            new_qrels[id][list(new_corpus.keys()).index(docid)] = val\n",
        "\n",
        "# Display a sample of the new qrels\n",
        "next(iter(new_qrels.items()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ONCq9-U05AJk",
        "outputId": "a8fd8fab-a517-47bf-fd3d-b2a160bbee2f"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0,\n",
              " {49745: 1,\n",
              "  32070: 2,\n",
              "  73068: 1,\n",
              "  108771: 1,\n",
              "  93770: 1,\n",
              "  16324: 1,\n",
              "  4871: 2,\n",
              "  32725: 1,\n",
              "  64315: 2,\n",
              "  37610: 1,\n",
              "  102952: 1,\n",
              "  56016: 2,\n",
              "  12020: 1,\n",
              "  38366: 2,\n",
              "  62557: 1,\n",
              "  19081: 1,\n",
              "  38431: 2,\n",
              "  46869: 1,\n",
              "  52860: 1,\n",
              "  107593: 1,\n",
              "  52202: 1,\n",
              "  4643: 2,\n",
              "  105760: 2,\n",
              "  113200: 1,\n",
              "  36073: 2,\n",
              "  431: 1,\n",
              "  65520: 1,\n",
              "  108446: 1,\n",
              "  30843: 1,\n",
              "  72985: 2,\n",
              "  47488: 2,\n",
              "  91427: 1,\n",
              "  36707: 1,\n",
              "  59909: 1,\n",
              "  47053: 1})"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### (3 points) Using the annotated set of queries, compute the Mean Average Precision (MAP) @100 as well as the average time per query."
      ],
      "metadata": {
        "id": "AJD4xqVMl9LX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "start = time()\n",
        "results = util.semantic_search(query_embeddings, corpus_embeddings, top_k=100, score_function=util.dot_score)\n",
        "end = time()\n",
        "\n",
        "avg_time = (end - start) / len(query_embeddings)\n",
        "\n",
        "print(\"The average time for {} queries is {:.4f} seconds\".format(len(query_embeddings), avg_time) )"
      ],
      "metadata": {
        "id": "it5hAVLCl6Rh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b8f79e86-340b-441f-f6ff-99572cc956b4"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The average time for 400 queries is 0.0002 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Let us see what results look like\n",
        "results[0][:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7KBeYWPbTmYK",
        "outputId": "ce9b5acf-6fc6-42cd-f0d9-15c9269c5d53"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'corpus_id': 65520, 'score': 0.613796055316925},\n",
              " {'corpus_id': 36073, 'score': 0.4821910560131073},\n",
              " {'corpus_id': 12020, 'score': 0.4738737940788269},\n",
              " {'corpus_id': 21630, 'score': 0.44950756430625916},\n",
              " {'corpus_id': 102342, 'score': 0.44849568605422974},\n",
              " {'corpus_id': 49745, 'score': 0.4403640925884247},\n",
              " {'corpus_id': 100599, 'score': 0.43535542488098145},\n",
              " {'corpus_id': 52860, 'score': 0.42014870047569275},\n",
              " {'corpus_id': 34606, 'score': 0.41908279061317444},\n",
              " {'corpus_id': 64315, 'score': 0.41114839911460876}]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def map_at_100(hits, qrels):\n",
        "    \"\"\"\n",
        "    Take the top hits for each query and returns the\n",
        "    Mean Average Precision for the top 100 ranks\n",
        "\n",
        "    Args:\n",
        "      - hits (list[list[dict[str, float]]]): The results of the query\n",
        "      - qrels (dict[int, list[dict[str, int]]]): The actual relevant documents\n",
        "    Returns:\n",
        "      The computed MAP@100 (float)\n",
        "\n",
        "    \"\"\"\n",
        "    MAP = 0\n",
        "    for query_id, _ in enumerate(hits):\n",
        "        avg_precision, relevants_docs, K = 0, 0, 0\n",
        "    \n",
        "        for doc in hits[query_id]:\n",
        "            K += 1\n",
        "\n",
        "            is_relevant = 1 if doc[\"corpus_id\"] in qrels[query_id] else 0\n",
        "            relevants_docs += is_relevant\n",
        "            precision = relevants_docs / K\n",
        "            avg_precision += precision * is_relevant\n",
        "\n",
        "        if relevants_docs > 0:\n",
        "            avg_precision /= relevants_docs\n",
        "\n",
        "        MAP += avg_precision\n",
        "    \n",
        "    return MAP / len(hits)\n",
        "\n",
        "MAP100 = map_at_100(results, new_qrels)\n",
        "\n",
        "print(\"The MAP@100 of our model is %.4f\" % MAP100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pB4FP6jaHe0a",
        "outputId": "6ae48102-0941-4153-c206-e302495acdb5"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The MAP@100 of our model is 0.6307\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## (4 points) Approximate nearest neighbours\n",
        "---"
      ],
      "metadata": {
        "id": "AZOBFXML83wJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### (3 points) Find a good set of parameters for the chosen ANN library and compute the MAP@100.\n"
      ],
      "metadata": {
        "id": "GXSQLqXd9DXB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import hnswlib"
      ],
      "metadata": {
        "id": "KAeWVd5IAqrH"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# HNSW doesn't support cuda tensors\n",
        "query_embeddings = query_embeddings.cpu()\n",
        "corpus_embeddings = corpus_embeddings.cpu()\n",
        "\n",
        "# 'ip' for Inner Product because we previously normalized embeddings\n",
        "index = hnswlib.Index(space = 'ip', dim = corpus_embeddings.shape[1])\n",
        "\n",
        "index.init_index(max_elements=corpus_embeddings.shape[0], ef_construction=400, M=64)\n",
        "\n",
        "index.add_items(corpus_embeddings, list(range(corpus_embeddings.shape[0])))"
      ],
      "metadata": {
        "id": "myD1stDN6QXF"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corpus_ids, scores = index.knn_query(query_embeddings, k=100)"
      ],
      "metadata": {
        "id": "cIeSePavGJX5"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We convert the results into a usable format\n",
        "ann_results = [[{\"corpus_id\":id} for id in doc] for doc in corpus_ids]\n",
        "\n",
        "MAP100 = map_at_100(ann_results, new_qrels)\n",
        "print(\"The MAP@100 for the ANN model is : %.4f\" % MAP100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aDnB69Lmlfy0",
        "outputId": "1a14f76f-afaa-4b09-be3e-6ab05c070b7c"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The MAP@100 for the ANN model is : 0.6275\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### (1 point) explain what the parameters you picked are, and why you chose them."
      ],
      "metadata": {
        "id": "PhvvxGlS9OX6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Les paramètres de notre modèle KNN sont :\n",
        "- `M` le nombre de liens bidirectionnels créés pour chaque nouvel élément pendant la construction. Ce paramètre ce situe généralement entre 2 et 100 et doit être proportionnel à la dimension des vecteurs.\n",
        "- `ef_construction` determine le rapport vitesse/accuracy lors de la construction du modèle, un plus grand `ef` impliquant une meilleure accuracy mais une recherche plus lente, et vice-versa.\n",
        "\n",
        "Nos vecteurs `corpus_embeddings` et `query_embeddings` ayant une taille élevée, il est conseillé pour `M` de prendre des valeurs entre *48* et *64*. Quant à `ef_construction`, il doit être supérieur au nombre de voisins qu'on souhaite retourner (100) et ne doit pas dépasser la taille du dataset. Nous prendrons donc une valeur suffisamment élevée dans cet intervalle pour conserver une bonne accuracy, la recherche étant déjà suffisamment rapide.\n",
        "\n",
        "En outre, nous avons repris les paramètres conseillés par les exemples de la documentation de Sentence-Transformers."
      ],
      "metadata": {
        "id": "yY4hoWozvDsz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### (Bonus) Play with these parameters and plot a speed vs MAP curve."
      ],
      "metadata": {
        "id": "BLKXpbaM9T57"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3IiHfgiVG-Sf"
      },
      "execution_count": 17,
      "outputs": []
    }
  ]
}